{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"train_ver2.csv\")\n",
    "#test_set = train_set.loc[train_set['fecha_dato']=='2016-04-28', :\"segmento\"]\n",
    "test_set = pd.read_csv(\"test_ver2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_list = ['fecha_alta', 'ult_fec_cli_1t', 'canal_entrada', 'cod_prov', 'indrel_1mes', 'conyuemp']\n",
    "train_set.drop(drop_list, axis=1, inplace=True)\n",
    "test_set.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_505 = train_set.loc[(train_set['fecha_dato']=='2015-05-28')]\n",
    "train_set_506 = train_set.loc[(train_set['fecha_dato']=='2015-06-28')]\n",
    "train_set_505.set_index('ncodpers', inplace=True)\n",
    "train_set_506.set_index('ncodpers', inplace=True)\n",
    "train_set_june = train_set_505.copy()\n",
    "train_set_june.loc[:, \"ind_ahor_fin_ult1\":\"ind_recibo_ult1\"] = train_set_506.loc[:, \"ind_ahor_fin_ult1\":\"ind_recibo_ult1\"] - train_set_505.loc[:, \"ind_ahor_fin_ult1\":\"ind_recibo_ult1\"]\n",
    "train_set_june.dropna(inplace=True)\n",
    "train_set_june['filter'] = train_set_june.loc[:, \"ind_ahor_fin_ult1\":\"ind_recibo_ult1\"].abs().sum(1)\n",
    "train_set_june = train_set_june[train_set_june['filter']>0]\n",
    "train_set_june_y = train_set_june.loc[:, \"ind_ahor_fin_ult1\":\"ind_recibo_ult1\"].copy().reset_index()\n",
    "train_set_june_y.loc[:, \"ind_ahor_fin_ult1\":\"ind_recibo_ult1\"] = (train_set_june_y.loc[:, \"ind_ahor_fin_ult1\":\"ind_recibo_ult1\"]>0).astype(float)\n",
    "train_set_june = train_set_june.loc[:, :\"segmento\"]\n",
    "train_set_june.reset_index(inplace=True)\n",
    "\n",
    "train_set_june.drop(['fecha_dato'], axis=1, inplace=True)\n",
    "test_set.drop(['fecha_dato'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_list = list(train_set.columns)[list(train_set.columns).index(\"ind_ahor_fin_ult1\"):list(train_set.columns).index(\"ind_recibo_ult1\")+1]\n",
    "def append_last_month(data_set, last_month): \n",
    "    return pd.merge(data_set, last_month.loc[:, ['ncodpers']+product_list].drop_duplicates(), how=\"inner\", on='ncodpers')\n",
    "    \n",
    "train_set_june = append_last_month(train_set_june, train_set.loc[(train_set['fecha_dato']=='2015-05-28')])\n",
    "test_set = append_last_month(test_set, train_set.loc[(train_set['fecha_dato']=='2016-05-28')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "province_code = train_set.groupby(\"nomprov\").agg({\"renta\":np.mean}).sort_values(by='renta', ascending=False).reset_index().reset_index().drop([\"renta\"], axis=1)\n",
    "province_code.columns = ['f_nomprov', \"nomprov\"]\n",
    "\n",
    "country_code = train_set.groupby('pais_residencia').agg({'renta':np.mean}).sort_values(by='renta', ascending=False).reset_index().reset_index().drop([\"renta\"], axis=1)\n",
    "country_code.columns = ['f_pais_residencia', \"pais_residencia\"]\n",
    "\n",
    "renta_missing = train_set_june['renta'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, column_name, value_set):\n",
    "    df1 = df.copy()\n",
    "    assert len(value_set)>1, \"len of value set should >1\"\n",
    "    if len(value_set)==2:\n",
    "        df1[\"f_{0}\".format(column_name)] = df1[column_name].apply(lambda x: 1 if x==value_set[0] else 0)\n",
    "    else:\n",
    "        for v in value_set:\n",
    "            df1[\"f_{0}_{1}\".format(column_name, v)] = df1[column_name].apply(lambda x: 1 if x==v else 0)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def encode_feature(X):\n",
    "    X1 = X.copy()\n",
    "    get_value_set = lambda x: list(train_set[x].drop_duplicates().dropna())\n",
    "    one_hot_encoding_list = [\"ind_empleado\", \"sexo\",  \"tiprel_1mes\", \"indresi\", \"indext\", \"indfall\", \"ind_actividad_cliente\", \"segmento\"]\n",
    "    for c in one_hot_encoding_list:\n",
    "        # print c\n",
    "        X1 = one_hot_encoding(X1, c, get_value_set(c))\n",
    "        gc.collect()\n",
    "    copy_feature_list = ['age', 'antiguedad', 'indrel', 'ind_nuevo', 'tipodom']\n",
    "    for c in copy_feature_list:\n",
    "        X1['f_'+c] = X1[c]  \n",
    "    X1 = pd.merge(X1, province_code, how=\"left\", on=['nomprov'])\n",
    "    X1 = X1.fillna(province_code['f_nomprov'].mean())\n",
    "    X1 = pd.merge(X1, country_code, how=\"left\", on=['pais_residencia'])\n",
    "    X1 = X1.fillna(country_code['f_pais_residencia'].mean())\n",
    "    X1['f_renta'] = (X1['renta'].apply(lambda x: renta_missing if \"NA\" in str(x) else x)).astype(float)\n",
    "    X1.drop(one_hot_encoding_list+copy_feature_list+['nomprov', 'pais_residencia', 'renta'], axis=1, inplace=True)\n",
    "    return X1\n",
    "\n",
    "train_feature = encode_feature(train_set_june)\n",
    "test_feature = encode_feature(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## new\n",
    "ma = train_feature['f_renta'].max()\n",
    "mm = train_feature['f_renta'].min()\n",
    "train_feature['f_renta'] = (train_feature['f_renta'] - mm)/(ma-mm)*2\n",
    "test_feature['f_renta'] = (test_feature['f_renta'] -mm)/(ma-mm)*2\n",
    "\n",
    "ma = train_feature['f_nomprov'].max()\n",
    "mm = train_feature['f_nomprov'].min()\n",
    "train_feature['f_nomprov'] =(train_feature['f_nomprov']- mm)/(ma-mm)*2\n",
    "test_feature['f_nomprov'] = (test_feature['f_nomprov']- mm)/(ma-mm)*2\n",
    "\n",
    "ma = train_feature['f_pais_residencia'].max()\n",
    "mm = train_feature['f_pais_residencia'].min()\n",
    "train_feature['f_pais_residencia'] = (train_feature['f_pais_residencia'] - mm)/(ma-mm)*2\n",
    "test_feature['f_pais_residencia'] = (test_feature['f_pais_residencia'] - mm)/(ma-mm)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44127\n",
      "44127\n",
      "929615\n"
     ]
    }
   ],
   "source": [
    "print len(train_feature)\n",
    "print len(train_set_june_y)\n",
    "train_feature = train_feature.sort_values(by='ncodpers')\n",
    "train_set_june_y = train_set_june_y.sort_values(by='ncodpers')\n",
    "X_train = np.array(train_feature.iloc[:, 1:].astype(float).values)\n",
    "y_train = np.array((train_set_june_y.iloc[:, 1:]>0).astype(int).values)\n",
    "X_test = np.array(test_feature.iloc[:, 1:].astype(float).values)\n",
    "print len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_n = []\n",
    "y_train_n = []\n",
    "for i, item in enumerate(X_train):\n",
    "    for k, y in enumerate(y_train[i]):\n",
    "        if y>0:\n",
    "            X_train_n.append(item)\n",
    "            y_train_n.append(k)\n",
    "X_train_n = np.array(X_train_n)\n",
    "y_train_n = np.array(y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "mu = X_train_n.mean(0)\n",
    "std = X_train_n.std(0)\n",
    "idx = np.argwhere(std==0)\n",
    "X_train_n = np.delete(X_train_n, idx, axis=1)\n",
    "X_test = np.delete(X_test, idx, axis=1)\n",
    "mu = X_train_n.mean(0)\n",
    "std = X_train_n.std(0)\n",
    "\n",
    "X_train_n = (X_train_n-mu)/std\n",
    "X_test = (X_test-mu)/std\n",
    "'''\n",
    "std = X_train_n.std(0)\n",
    "idx = np.argwhere(std==0)\n",
    "X_train_n = np.delete(X_train_n, idx, axis=1)\n",
    "X_test = np.delete(X_test, idx, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.43304413e-03,  -1.28751215e-02,   1.18011168e+00, ...,\n",
       "         -7.01053318e-01,   5.25588331e-03,   7.15122699e-01],\n",
       "       [ -7.43304413e-03,  -1.28751215e-02,   1.18011168e+00, ...,\n",
       "          1.62057375e+00,   5.25588331e-03,   1.06238049e-03],\n",
       "       [ -7.43304413e-03,  -1.28751215e-02,   1.18011168e+00, ...,\n",
       "          2.47003725e-03,   5.25588331e-03,   1.06238049e-03],\n",
       "       ..., \n",
       "       [ -7.43304413e-03,  -1.28751215e-02,   1.18011168e+00, ...,\n",
       "          6.35641057e-01,   5.25588331e-03,  -2.75617089e-01],\n",
       "       [ -7.43304413e-03,  -1.28751215e-02,   1.18011168e+00, ...,\n",
       "          6.35641057e-01,   5.25588331e-03,   1.65827910e-02],\n",
       "       [ -7.43304413e-03,  -1.28751215e-02,  -8.47377426e-01, ...,\n",
       "          2.11304010e+00,   5.25588331e-03,   1.06238049e-03]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"../data/train_ver2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(class_weight=None, multi_class='multinomial', solver=\"lbfgs\", penalty='l2')\n",
    "model = model.fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = np.hstack([np.zeros((predict.shape[0],2)), predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929615\n"
     ]
    }
   ],
   "source": [
    "filter1 = np.array((test_feature.loc[:, product_list]==0).values)\n",
    "predict = predict*filter1\n",
    "user_id = list(test_set[\"ncodpers\"])\n",
    "\n",
    "f = open(\"softmax_sub.csv\", 'w')\n",
    "f.write(\"ncodpers,added_products\\n\")\n",
    "\n",
    "print len(predict)\n",
    "\n",
    "for idx,r in enumerate(predict):\n",
    "    order = [i[0] for i in sorted(enumerate(r), key=lambda x:x[1], reverse=True)]\n",
    "    select = order[:min(7,len(order))]\n",
    "    f.write(str(user_id[idx])+\",\"+(\" \".join([product_list[s] for s in select]))+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ncodpers                                                       30991704659\n",
       "ind_empleado             NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...\n",
       "pais_residencia          ESESESESESESESESESESESESESESESESESESESESESESES...\n",
       "sexo                     VHVVVVHHVHHVVHVHVHHVVHHVHVVVVVHHHVHVVHHVVHHVVV...\n",
       "age                       24 27 23 40 24 23 24 31 23 23 31 25 35 24 26 ...\n",
       "ind_nuevo                                                             2356\n",
       "antiguedad                    34     34     34     34     34     34    ...\n",
       "indrel                                                               44127\n",
       "tiprel_1mes              AAIAAAAAAIAAAAAAIAAAAAAAAAAAAAAAAAAAAIAAAAAAAA...\n",
       "indresi                  SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS...\n",
       "indext                   NNNNNNNNNSNNNNNNNSNNNNNNNNNNNNNNNNNNNNNNSNNSNN...\n",
       "indfall                  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN...\n",
       "tipodom                                                              44127\n",
       "nomprov                  MADRIDMADRIDMADRIDSEVILLAMADRIDOURENSECADIZJAE...\n",
       "ind_actividad_cliente                                                41409\n",
       "renta                                                           6.3331e+09\n",
       "segmento                 03 - UNIVERSITARIO03 - UNIVERSITARIO03 - UNIVE...\n",
       "ind_ahor_fin_ult1                                                        7\n",
       "ind_aval_fin_ult1                                                        5\n",
       "ind_cco_fin_ult1                                                     22267\n",
       "ind_cder_fin_ult1                                                       42\n",
       "ind_cno_fin_ult1                                                     19975\n",
       "ind_ctju_fin_ult1                                                       91\n",
       "ind_ctma_fin_ult1                                                     1057\n",
       "ind_ctop_fin_ult1                                                     7807\n",
       "ind_ctpp_fin_ult1                                                     5368\n",
       "ind_deco_fin_ult1                                                      704\n",
       "ind_deme_fin_ult1                                                      188\n",
       "ind_dela_fin_ult1                                                     5452\n",
       "ind_ecue_fin_ult1                                                    11735\n",
       "ind_fond_fin_ult1                                                     2342\n",
       "ind_hip_fin_ult1                                                       868\n",
       "ind_plan_fin_ult1                                                     1168\n",
       "ind_pres_fin_ult1                                                      135\n",
       "ind_reca_fin_ult1                                                     7647\n",
       "ind_tjcr_fin_ult1                                                     9387\n",
       "ind_valo_fin_ult1                                                     3534\n",
       "ind_viv_fin_ult1                                                       375\n",
       "ind_nomina_ult1                                                       9303\n",
       "ind_nom_pens_ult1                                                     9515\n",
       "ind_recibo_ult1                                                      22328\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_june.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"simple_sub.csv\", 'w')\n",
    "f.write(\"ncodpers,added_products\\n\")\n",
    "for code in list(test_set['ncodpers']):\n",
    "    f.write(str(code)+\",ind_recibo_ult1 ind_cco_fin_ult1 ind_cno_fin_ult1 ind_ecue_fin_ult1 ind_nom_pens_ult1 ind_tjcr_fin_ult1 ind_nomina_ult1\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
